model_id: phi3-mini
provider: hf
context_window: 4096

# Core inference parameters
temperature: 0.0
max_tokens: 256

# Advanced parameters
additional_params: {}

# Model capabilities
capabilities:
  multilingual: true

# HuggingFace configuration
# Use hf_model_name for public Inference API, or hf_endpoint_url for dedicated endpoints
hf_model_name: microsoft/Phi-3-mini-4k-instruct
# hf_endpoint_url: https://your-endpoint.aws.endpoints.huggingface.cloud
