{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "EvaluationMetrics",
  "description": "Placeholder schema for evaluate CLI output. TODO: Define based on metrics computation implementation.",
  "type": "object",
  "properties": {
    "accuracy": {
      "type": "number",
      "minimum": 0.0,
      "maximum": 1.0,
      "description": "Overall accuracy"
    },
    "macro_f1": {
      "type": "number",
      "minimum": 0.0,
      "maximum": 1.0,
      "description": "Macro-averaged F1 score"
    },
    "micro_f1": {
      "type": "number",
      "minimum": 0.0,
      "maximum": 1.0,
      "description": "Micro-averaged F1 score"
    },
    "per_class_metrics": {
      "type": "object",
      "description": "Metrics broken down by class (0, 1, 2)",
      "patternProperties": {
        "^[0-2]$": {
          "type": "object",
          "properties": {
            "precision": {"type": "number"},
            "recall": {"type": "number"},
            "f1": {"type": "number"},
            "support": {"type": "integer"}
          }
        }
      }
    },
    "confusion_matrix": {
      "type": "array",
      "description": "3x3 confusion matrix for relevance labels [0, 1, 2]",
      "items": {
        "type": "array",
        "items": {"type": "integer"},
        "minItems": 3,
        "maxItems": 3
      },
      "minItems": 3,
      "maxItems": 3
    }
  }
}
