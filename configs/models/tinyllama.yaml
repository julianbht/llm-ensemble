model_id: tinyllama
provider: ollama
context_window: 2048

# Core inference parameters
temperature: 0.0
max_tokens: 256

# Advanced parameters
additional_params: {}

# Model capabilities
capabilities:
  multilingual: false
